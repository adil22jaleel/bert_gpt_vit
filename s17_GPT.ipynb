{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dfb5c9d9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OsfzQJD4lB2z",
    "outputId": "d5a5ce00-ca62-4ba7-9284-dc17fd1dc1a5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Downloading transformers-4.33.2-py3-none-any.whl (7.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m70.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.2)\n",
      "Collecting huggingface-hub<1.0,>=0.15.1 (from transformers)\n",
      "  Downloading huggingface_hub-0.17.1-py3-none-any.whl (294 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.8/294.8 kB\u001b[0m \u001b[31m35.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
      "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers)\n",
      "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m56.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting safetensors>=0.3.1 (from transformers)\n",
      "  Downloading safetensors-0.3.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m77.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (2023.6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (4.5.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n",
      "Installing collected packages: tokenizers, safetensors, huggingface-hub, transformers\n",
      "Successfully installed huggingface-hub-0.17.1 safetensors-0.3.3 tokenizers-0.13.3 transformers-4.33.2\n"
     ]
    }
   ],
   "source": [
    "\n",
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7813ec33",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NbpqQWKUlIjZ",
    "outputId": "4a82d7fd-3e6e-417a-ee67-f7ec813963bc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'bert_gpt_vit'...\n",
      "remote: Enumerating objects: 372, done.\u001b[K\n",
      "remote: Counting objects: 100% (92/92), done.\u001b[K\n",
      "remote: Compressing objects: 100% (90/90), done.\u001b[K\n",
      "remote: Total 372 (delta 5), reused 85 (delta 2), pack-reused 280\u001b[K\n",
      "Receiving objects: 100% (372/372), 17.08 MiB | 14.24 MiB/s, done.\n",
      "Resolving deltas: 100% (13/13), done.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "!git clone https://github.com/adil22jaleel/bert_gpt_vit.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4382515f",
   "metadata": {
    "id": "di-hmXl8l_Tk"
   },
   "outputs": [],
   "source": [
    "from bert_gpt_vit.transformers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2594ca29",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FlJm-Q-gupCg",
    "outputId": "c9ba441d-cb5e-416b-bdc0-e1255e350a45"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (37443 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:          1 | Train Loss 10.7307 | Validation Loss 10.7208\n",
      "Iteration:          2 | Train Loss 9.5013 | Validation Loss 9.5431\n",
      "Iteration:          3 | Train Loss 10.3556 | Validation Loss 10.5411\n",
      "Iteration:          4 | Train Loss 9.6130 | Validation Loss 9.7921\n",
      "Iteration:          5 | Train Loss 9.5026 | Validation Loss 9.7503\n",
      "Iteration:          6 | Train Loss 9.1903 | Validation Loss 9.5038\n",
      "Iteration:          7 | Train Loss 8.5632 | Validation Loss 8.9381\n",
      "Iteration:          8 | Train Loss 8.4724 | Validation Loss 8.8679\n",
      "Iteration:          9 | Train Loss 7.8931 | Validation Loss 8.3344\n",
      "Iteration:         10 | Train Loss 7.5371 | Validation Loss 8.2155\n",
      "Iteration:         11 | Train Loss 7.4141 | Validation Loss 8.0594\n",
      "Iteration:         12 | Train Loss 7.2912 | Validation Loss 7.8331\n",
      "Iteration:         13 | Train Loss 7.0710 | Validation Loss 7.7691\n",
      "Iteration:         14 | Train Loss 6.8637 | Validation Loss 7.5047\n",
      "Iteration:         15 | Train Loss 6.6007 | Validation Loss 7.3123\n",
      "Iteration:         16 | Train Loss 6.4860 | Validation Loss 7.1017\n",
      "Iteration:         17 | Train Loss 6.3251 | Validation Loss 6.9643\n",
      "Iteration:         18 | Train Loss 6.3350 | Validation Loss 7.0067\n",
      "Iteration:         19 | Train Loss 6.2294 | Validation Loss 6.9852\n",
      "Iteration:         20 | Train Loss 6.1243 | Validation Loss 6.8127\n",
      "Iteration:         21 | Train Loss 6.0639 | Validation Loss 6.8523\n",
      "Iteration:         22 | Train Loss 6.0586 | Validation Loss 6.8180\n",
      "Iteration:         23 | Train Loss 5.9853 | Validation Loss 6.7866\n",
      "Iteration:         24 | Train Loss 5.9596 | Validation Loss 6.7722\n",
      "Iteration:         25 | Train Loss 5.8425 | Validation Loss 6.7484\n",
      "Iteration:         26 | Train Loss 5.8779 | Validation Loss 6.7485\n",
      "Iteration:         27 | Train Loss 5.7603 | Validation Loss 6.6943\n",
      "Iteration:         28 | Train Loss 5.7483 | Validation Loss 6.6973\n",
      "Iteration:         29 | Train Loss 5.7411 | Validation Loss 6.6136\n",
      "Iteration:         30 | Train Loss 5.6809 | Validation Loss 6.7043\n",
      "Iteration:         31 | Train Loss 5.6464 | Validation Loss 6.6060\n",
      "Iteration:         32 | Train Loss 5.6324 | Validation Loss 6.5877\n",
      "Iteration:         33 | Train Loss 5.5502 | Validation Loss 6.5907\n",
      "Iteration:         34 | Train Loss 5.5381 | Validation Loss 6.5898\n",
      "Iteration:         35 | Train Loss 5.5554 | Validation Loss 6.4493\n",
      "Iteration:         36 | Train Loss 5.5074 | Validation Loss 6.5136\n",
      "Iteration:         37 | Train Loss 5.4550 | Validation Loss 6.4740\n",
      "Iteration:         38 | Train Loss 5.4620 | Validation Loss 6.4755\n",
      "Iteration:         39 | Train Loss 5.4007 | Validation Loss 6.4616\n",
      "Iteration:         40 | Train Loss 5.3931 | Validation Loss 6.4613\n",
      "Iteration:         41 | Train Loss 5.2273 | Validation Loss 6.3655\n",
      "Iteration:         42 | Train Loss 5.2359 | Validation Loss 6.4804\n",
      "Iteration:         43 | Train Loss 5.3021 | Validation Loss 6.5118\n",
      "Iteration:         44 | Train Loss 5.3152 | Validation Loss 6.4989\n",
      "Iteration:         45 | Train Loss 5.2284 | Validation Loss 6.3456\n",
      "Iteration:         46 | Train Loss 5.0637 | Validation Loss 6.3576\n",
      "Iteration:         47 | Train Loss 5.1728 | Validation Loss 6.3588\n",
      "Iteration:         48 | Train Loss 5.1352 | Validation Loss 6.4111\n",
      "Iteration:         49 | Train Loss 5.0955 | Validation Loss 6.3523\n",
      "Iteration:         50 | Train Loss 5.0680 | Validation Loss 6.3136\n",
      "Iteration:         51 | Train Loss 5.1039 | Validation Loss 6.4293\n",
      "Iteration:         52 | Train Loss 5.1397 | Validation Loss 6.2667\n",
      "Iteration:         53 | Train Loss 4.9910 | Validation Loss 6.3667\n",
      "Iteration:         54 | Train Loss 5.0064 | Validation Loss 6.2780\n",
      "Iteration:         55 | Train Loss 5.0531 | Validation Loss 6.2804\n",
      "Iteration:         56 | Train Loss 4.9216 | Validation Loss 6.3656\n",
      "Iteration:         57 | Train Loss 4.8816 | Validation Loss 6.2853\n",
      "Iteration:         58 | Train Loss 4.8878 | Validation Loss 6.2876\n",
      "Iteration:         59 | Train Loss 4.8754 | Validation Loss 6.3182\n",
      "Iteration:         60 | Train Loss 4.7735 | Validation Loss 6.2465\n",
      "Iteration:         61 | Train Loss 4.8333 | Validation Loss 6.2274\n",
      "Iteration:         62 | Train Loss 4.8190 | Validation Loss 6.2014\n",
      "Iteration:         63 | Train Loss 4.8129 | Validation Loss 6.2501\n",
      "Iteration:         64 | Train Loss 4.7701 | Validation Loss 6.2838\n",
      "Iteration:         65 | Train Loss 4.7291 | Validation Loss 6.2297\n",
      "Iteration:         66 | Train Loss 4.6786 | Validation Loss 6.2174\n",
      "Iteration:         67 | Train Loss 4.7225 | Validation Loss 6.1974\n",
      "Iteration:         68 | Train Loss 4.6314 | Validation Loss 6.2400\n",
      "Iteration:         69 | Train Loss 4.5794 | Validation Loss 6.2333\n",
      "Iteration:         70 | Train Loss 4.6602 | Validation Loss 6.1783\n",
      "Iteration:         71 | Train Loss 4.5355 | Validation Loss 6.1370\n",
      "Iteration:         72 | Train Loss 4.6391 | Validation Loss 6.1456\n",
      "Iteration:         73 | Train Loss 4.6191 | Validation Loss 6.2109\n",
      "Iteration:         74 | Train Loss 4.5799 | Validation Loss 6.2420\n",
      "Iteration:         75 | Train Loss 4.5294 | Validation Loss 6.2051\n",
      "Iteration:         76 | Train Loss 4.5443 | Validation Loss 6.2724\n",
      "Iteration:         77 | Train Loss 4.4018 | Validation Loss 6.1808\n",
      "Iteration:         78 | Train Loss 4.4583 | Validation Loss 6.2025\n",
      "Iteration:         79 | Train Loss 4.4244 | Validation Loss 6.2214\n",
      "Iteration:         80 | Train Loss 4.4230 | Validation Loss 6.2273\n",
      "Iteration:         81 | Train Loss 4.4291 | Validation Loss 6.1824\n",
      "Iteration:         82 | Train Loss 4.3661 | Validation Loss 6.1593\n",
      "Iteration:         83 | Train Loss 4.4440 | Validation Loss 6.1871\n",
      "Iteration:         84 | Train Loss 4.4291 | Validation Loss 6.2481\n",
      "Iteration:         85 | Train Loss 4.3812 | Validation Loss 6.1480\n",
      "Iteration:         86 | Train Loss 4.3373 | Validation Loss 6.1964\n",
      "Iteration:         87 | Train Loss 4.2981 | Validation Loss 6.1701\n",
      "Iteration:         88 | Train Loss 4.2600 | Validation Loss 6.2470\n",
      "Iteration:         89 | Train Loss 4.3468 | Validation Loss 6.2670\n",
      "Iteration:         90 | Train Loss 4.2741 | Validation Loss 6.1685\n",
      "Iteration:         91 | Train Loss 4.2320 | Validation Loss 6.2402\n",
      "Iteration:         92 | Train Loss 4.2537 | Validation Loss 6.1799\n",
      "Iteration:         93 | Train Loss 4.1993 | Validation Loss 6.2099\n",
      "Iteration:         94 | Train Loss 4.2736 | Validation Loss 6.1614\n",
      "Iteration:         95 | Train Loss 4.2127 | Validation Loss 6.1490\n",
      "Iteration:         96 | Train Loss 4.1582 | Validation Loss 6.1656\n",
      "Iteration:         97 | Train Loss 4.0377 | Validation Loss 6.0935\n",
      "Iteration:         98 | Train Loss 4.1644 | Validation Loss 6.1639\n",
      "Iteration:         99 | Train Loss 4.1090 | Validation Loss 6.2554\n",
      "Iteration:        100 | Train Loss 4.1930 | Validation Loss 6.1807\n",
      "Iteration:        101 | Train Loss 4.0702 | Validation Loss 6.2253\n",
      "Iteration:        102 | Train Loss 4.0895 | Validation Loss 6.2068\n",
      "Iteration:        103 | Train Loss 4.0412 | Validation Loss 6.1415\n",
      "Iteration:        104 | Train Loss 3.9899 | Validation Loss 6.1279\n",
      "Iteration:        105 | Train Loss 3.9705 | Validation Loss 6.2563\n",
      "Iteration:        106 | Train Loss 4.0208 | Validation Loss 6.2548\n",
      "Iteration:        107 | Train Loss 4.0237 | Validation Loss 6.1885\n",
      "Iteration:        108 | Train Loss 4.0098 | Validation Loss 6.2574\n",
      "Iteration:        109 | Train Loss 3.9625 | Validation Loss 6.2318\n",
      "Iteration:        110 | Train Loss 3.9690 | Validation Loss 6.1850\n",
      "Iteration:        111 | Train Loss 3.8801 | Validation Loss 6.1146\n",
      "Iteration:        112 | Train Loss 3.9554 | Validation Loss 6.2022\n",
      "Iteration:        113 | Train Loss 3.9024 | Validation Loss 6.2127\n",
      "Iteration:        114 | Train Loss 3.9477 | Validation Loss 6.1867\n",
      "Iteration:        115 | Train Loss 3.8517 | Validation Loss 6.1178\n",
      "Iteration:        116 | Train Loss 3.9209 | Validation Loss 6.1918\n",
      "Iteration:        117 | Train Loss 3.8539 | Validation Loss 6.1875\n",
      "Iteration:        118 | Train Loss 3.9082 | Validation Loss 6.1916\n",
      "Iteration:        119 | Train Loss 3.8057 | Validation Loss 6.2022\n",
      "Iteration:        120 | Train Loss 3.8517 | Validation Loss 6.1434\n",
      "Iteration:        121 | Train Loss 3.8410 | Validation Loss 6.1619\n",
      "Iteration:        122 | Train Loss 3.8412 | Validation Loss 6.1641\n",
      "Iteration:        123 | Train Loss 3.8532 | Validation Loss 6.1370\n",
      "Iteration:        124 | Train Loss 3.7863 | Validation Loss 6.1602\n",
      "Iteration:        125 | Train Loss 3.6809 | Validation Loss 6.2266\n",
      "Iteration:        126 | Train Loss 3.7693 | Validation Loss 6.1049\n",
      "Iteration:        127 | Train Loss 3.7193 | Validation Loss 6.1708\n",
      "Iteration:        128 | Train Loss 3.7093 | Validation Loss 6.2665\n",
      "Iteration:        129 | Train Loss 3.7896 | Validation Loss 6.1777\n",
      "Iteration:        130 | Train Loss 3.7764 | Validation Loss 6.1472\n",
      "Iteration:        131 | Train Loss 3.7814 | Validation Loss 6.2045\n",
      "Iteration:        132 | Train Loss 3.6881 | Validation Loss 6.2342\n",
      "Iteration:        133 | Train Loss 3.6962 | Validation Loss 6.1927\n",
      "Iteration:        134 | Train Loss 3.6375 | Validation Loss 6.1620\n",
      "Iteration:        135 | Train Loss 3.7206 | Validation Loss 6.2126\n",
      "Iteration:        136 | Train Loss 3.6487 | Validation Loss 6.2525\n",
      "Iteration:        137 | Train Loss 3.6201 | Validation Loss 6.3392\n",
      "Iteration:        138 | Train Loss 3.6115 | Validation Loss 6.2740\n",
      "Iteration:        139 | Train Loss 3.6320 | Validation Loss 6.1921\n",
      "Iteration:        140 | Train Loss 3.5787 | Validation Loss 6.3082\n",
      "Iteration:        141 | Train Loss 3.6200 | Validation Loss 6.3888\n",
      "Iteration:        142 | Train Loss 3.6459 | Validation Loss 6.3295\n",
      "Iteration:        143 | Train Loss 3.5430 | Validation Loss 6.2046\n",
      "Iteration:        144 | Train Loss 3.4676 | Validation Loss 6.1800\n",
      "Iteration:        145 | Train Loss 3.5794 | Validation Loss 6.2550\n",
      "Iteration:        146 | Train Loss 3.4613 | Validation Loss 6.2152\n",
      "Iteration:        147 | Train Loss 3.4983 | Validation Loss 6.1668\n",
      "Iteration:        148 | Train Loss 3.5134 | Validation Loss 6.2373\n",
      "Iteration:        149 | Train Loss 3.4526 | Validation Loss 6.2148\n",
      "Iteration:        150 | Train Loss 3.4505 | Validation Loss 6.2137\n",
      "Iteration:        151 | Train Loss 3.4789 | Validation Loss 6.2485\n",
      "Iteration:        152 | Train Loss 3.4645 | Validation Loss 6.1074\n",
      "Iteration:        153 | Train Loss 3.4720 | Validation Loss 6.3129\n",
      "Iteration:        154 | Train Loss 3.4892 | Validation Loss 6.3070\n",
      "Iteration:        155 | Train Loss 3.3558 | Validation Loss 6.2926\n",
      "Iteration:        156 | Train Loss 3.4151 | Validation Loss 6.2569\n",
      "Iteration:        157 | Train Loss 3.4000 | Validation Loss 6.3073\n",
      "Iteration:        158 | Train Loss 3.3486 | Validation Loss 6.2919\n",
      "Iteration:        159 | Train Loss 3.3422 | Validation Loss 6.2437\n",
      "Iteration:        160 | Train Loss 3.3662 | Validation Loss 6.2470\n",
      "Iteration:        161 | Train Loss 3.3780 | Validation Loss 6.2647\n",
      "Iteration:        162 | Train Loss 3.4057 | Validation Loss 6.3304\n",
      "Iteration:        163 | Train Loss 3.3578 | Validation Loss 6.3758\n",
      "Iteration:        164 | Train Loss 3.2805 | Validation Loss 6.3085\n",
      "Iteration:        165 | Train Loss 3.2437 | Validation Loss 6.3630\n",
      "Iteration:        166 | Train Loss 3.3245 | Validation Loss 6.3271\n",
      "Iteration:        167 | Train Loss 3.2244 | Validation Loss 6.2958\n",
      "Iteration:        168 | Train Loss 3.2719 | Validation Loss 6.3917\n",
      "Iteration:        169 | Train Loss 3.2219 | Validation Loss 6.3086\n",
      "Iteration:        170 | Train Loss 3.2680 | Validation Loss 6.2971\n",
      "Iteration:        171 | Train Loss 3.2344 | Validation Loss 6.4218\n",
      "Iteration:        172 | Train Loss 3.2228 | Validation Loss 6.3094\n",
      "Iteration:        173 | Train Loss 3.2755 | Validation Loss 6.3578\n",
      "Iteration:        174 | Train Loss 3.2135 | Validation Loss 6.2826\n",
      "Iteration:        175 | Train Loss 3.1758 | Validation Loss 6.3510\n",
      "Iteration:        176 | Train Loss 3.2245 | Validation Loss 6.3083\n",
      "Iteration:        177 | Train Loss 3.2387 | Validation Loss 6.3560\n",
      "Iteration:        178 | Train Loss 3.2255 | Validation Loss 6.3117\n",
      "Iteration:        179 | Train Loss 3.1654 | Validation Loss 6.2603\n",
      "Iteration:        180 | Train Loss 3.1788 | Validation Loss 6.3436\n",
      "Iteration:        181 | Train Loss 3.1555 | Validation Loss 6.4482\n",
      "Iteration:        182 | Train Loss 3.1034 | Validation Loss 6.2358\n",
      "Iteration:        183 | Train Loss 3.1856 | Validation Loss 6.3348\n",
      "Iteration:        184 | Train Loss 3.1535 | Validation Loss 6.4643\n",
      "Iteration:        185 | Train Loss 3.1204 | Validation Loss 6.3041\n",
      "Iteration:        186 | Train Loss 3.0918 | Validation Loss 6.2420\n",
      "Iteration:        187 | Train Loss 3.1852 | Validation Loss 6.3479\n",
      "Iteration:        188 | Train Loss 3.1091 | Validation Loss 6.3253\n",
      "Iteration:        189 | Train Loss 3.0549 | Validation Loss 6.3253\n",
      "Iteration:        190 | Train Loss 3.1014 | Validation Loss 6.3253\n",
      "Iteration:        191 | Train Loss 3.0546 | Validation Loss 6.4714\n",
      "Iteration:        192 | Train Loss 3.0979 | Validation Loss 6.4607\n",
      "Iteration:        193 | Train Loss 3.0123 | Validation Loss 6.4236\n",
      "Iteration:        194 | Train Loss 3.0887 | Validation Loss 6.3251\n",
      "Iteration:        195 | Train Loss 3.0801 | Validation Loss 6.3212\n",
      "Iteration:        196 | Train Loss 3.0258 | Validation Loss 6.3620\n",
      "Iteration:        197 | Train Loss 2.9947 | Validation Loss 6.2805\n",
      "Iteration:        198 | Train Loss 3.0003 | Validation Loss 6.3908\n",
      "Iteration:        199 | Train Loss 3.0767 | Validation Loss 6.3822\n",
      "Iteration:        200 | Train Loss 3.0203 | Validation Loss 6.3726\n",
      "Iteration:        201 | Train Loss 2.9173 | Validation Loss 6.3630\n",
      "Iteration:        202 | Train Loss 2.9145 | Validation Loss 6.4671\n",
      "Iteration:        203 | Train Loss 2.9606 | Validation Loss 6.4172\n",
      "Iteration:        204 | Train Loss 2.9709 | Validation Loss 6.4183\n",
      "Iteration:        205 | Train Loss 2.9272 | Validation Loss 6.4857\n",
      "Iteration:        206 | Train Loss 2.9992 | Validation Loss 6.4680\n",
      "Iteration:        207 | Train Loss 2.9984 | Validation Loss 6.4959\n",
      "Iteration:        208 | Train Loss 2.9107 | Validation Loss 6.6739\n",
      "Iteration:        209 | Train Loss 2.8350 | Validation Loss 6.4895\n",
      "Iteration:        210 | Train Loss 2.8457 | Validation Loss 6.3396\n",
      "Iteration:        211 | Train Loss 2.9249 | Validation Loss 6.4212\n",
      "Iteration:        212 | Train Loss 2.8849 | Validation Loss 6.5468\n",
      "Iteration:        213 | Train Loss 2.8049 | Validation Loss 6.3226\n",
      "Iteration:        214 | Train Loss 2.7973 | Validation Loss 6.3384\n",
      "Iteration:        215 | Train Loss 2.8980 | Validation Loss 6.3937\n",
      "Iteration:        216 | Train Loss 2.7649 | Validation Loss 6.3913\n",
      "Iteration:        217 | Train Loss 2.7962 | Validation Loss 6.3966\n",
      "Iteration:        218 | Train Loss 2.7987 | Validation Loss 6.2833\n",
      "Iteration:        219 | Train Loss 2.7219 | Validation Loss 6.3492\n",
      "Iteration:        220 | Train Loss 2.8356 | Validation Loss 6.4653\n",
      "Iteration:        221 | Train Loss 2.8528 | Validation Loss 6.3568\n",
      "Iteration:        222 | Train Loss 2.7581 | Validation Loss 6.4457\n",
      "Iteration:        223 | Train Loss 2.6867 | Validation Loss 6.5852\n",
      "Iteration:        224 | Train Loss 2.7366 | Validation Loss 6.4645\n",
      "Iteration:        225 | Train Loss 2.7490 | Validation Loss 6.5088\n",
      "Iteration:        226 | Train Loss 2.6869 | Validation Loss 6.5132\n",
      "Iteration:        227 | Train Loss 2.6636 | Validation Loss 6.4791\n",
      "Iteration:        228 | Train Loss 2.6939 | Validation Loss 6.5453\n",
      "Iteration:        229 | Train Loss 2.7103 | Validation Loss 6.5107\n",
      "Iteration:        230 | Train Loss 2.7008 | Validation Loss 6.4825\n",
      "Iteration:        231 | Train Loss 2.6480 | Validation Loss 6.3979\n",
      "Iteration:        232 | Train Loss 2.7001 | Validation Loss 6.6115\n",
      "Iteration:        233 | Train Loss 2.6364 | Validation Loss 6.4800\n",
      "Iteration:        234 | Train Loss 2.6516 | Validation Loss 6.5324\n",
      "Iteration:        235 | Train Loss 2.6101 | Validation Loss 6.5856\n",
      "Iteration:        236 | Train Loss 2.5883 | Validation Loss 6.5621\n",
      "Iteration:        237 | Train Loss 2.5884 | Validation Loss 6.3255\n",
      "Iteration:        238 | Train Loss 2.6290 | Validation Loss 6.5534\n",
      "Iteration:        239 | Train Loss 2.6220 | Validation Loss 6.6908\n",
      "Iteration:        240 | Train Loss 2.6259 | Validation Loss 6.5190\n",
      "Iteration:        241 | Train Loss 2.6332 | Validation Loss 6.4944\n",
      "Iteration:        242 | Train Loss 2.5699 | Validation Loss 6.5831\n",
      "Iteration:        243 | Train Loss 2.5515 | Validation Loss 6.5357\n",
      "Iteration:        244 | Train Loss 2.5824 | Validation Loss 6.6013\n",
      "Iteration:        245 | Train Loss 2.5224 | Validation Loss 6.4881\n",
      "Iteration:        246 | Train Loss 2.5619 | Validation Loss 6.6376\n",
      "Iteration:        247 | Train Loss 2.5360 | Validation Loss 6.4721\n",
      "Iteration:        248 | Train Loss 2.4306 | Validation Loss 6.5773\n",
      "Iteration:        249 | Train Loss 2.5353 | Validation Loss 6.5059\n",
      "Iteration:        250 | Train Loss 2.4792 | Validation Loss 6.5251\n"
     ]
    }
   ],
   "source": [
    "transformers_combined(\"GPT\",250)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
